---
title: "Prévision"
toc: true
editor: 
  markdown: 
    wrap: 72
---

Mon travail de prévision se concentre sur **la prévision robuste
orientée vers la décision**, où l'interprétabilité, la stabilité à
travers les saisons et les hypothèses réalistes comptent plus que les
gains marginaux de précision.

Le projet suivant est basé sur une étude complète de bout en bout de
prévision de la demande d'électricité menée sur **10 ans de données de
charge horaire** pour un grand fournisseur d'énergie américain. Il
démontre comment **les contraintes opérationnelles, la quantification de
l'incertitude et la robustesse du modèle** doivent guider la
méthodologie de prévision—pas seulement les métriques de performance
statistique.

------------------------------------------------------------------------

## Prévision de la demande d'électricité — JC Power & Light (NJ)

### Contexte

Jersey Central Power & Light (JCP&L) dessert environ **1,1 million de
clients** sur **3 200 miles carrés** dans le New Jersey, représentant
environ **12% de la population de l'État**. Le mix électrique est dominé
par **le gaz naturel et le nucléaire**, avec des énergies renouvelables
limitées, conduisant à une forte sensibilité météorologique.

![Carte de la zone de service JCP&L dans le réseau
PJM](../assets/forecasting/jcpl.png) *Territoire de service de
FirstEnergy montrant la zone JCP&L (en jaune) dans le New Jersey*

![Comtés desservis par JCP&L au New
Jersey](../assets/forecasting/nj2.png) *Détail des régions du New Jersey
couvertes par JCP&L*

L'objectif opérationnel était **la prévision de charge à court terme**
qui reste fiable à travers : - **Les transitions saisonnières** (demande
de chauffage vs. climatisation), - **Les événements météorologiques
extrêmes** (canicules, vagues de froid, tempêtes), - **Les changements
structurels** (modernisation du réseau, programmes de réponse à la
demande, changements économiques).

Ce n'est pas un exercice académique visant à minimiser le MAPE sur un
ensemble de test. Il s'agit de **construire des prévisions auxquelles
les opérateurs font confiance, qui survivent aux cas limites, et qui se
dégradent gracieusement lorsque les hypothèses se brisent**.

------------------------------------------------------------------------

### Données & analyse exploratoire

**Caractéristiques du jeu de données :** - **10 ans de données de charge
horaire** (≈ 87 600 observations) - Aucune valeur manquante - Forte
**saisonnalité hebdomadaire et annuelle** - Corrélation claire avec les
variables météorologiques (température, neige, précipitations) -
Plusieurs **événements de panne majeurs**, audités manuellement et
imputés lorsqu'ils avaient un impact mesurable sur la charge de pointe

![Données d'entraînement et de validation - Demande
horaire](../assets/forecasting/datasplit.png) *Séries temporelles
d'entraînement (2015-2019) et de validation (2020-2024)*

**Résultats exploratoires :**

**Schémas de saisonnalité :** - **Pics hivernaux** dus à la demande de
chauffage (gaz naturel, chauffage électrique) - **Pics estivaux** dus à
la demande de climatisation (saturation de la climatisation) - **Saisons
intermédiaires** (Printemps/Automne) avec une demande globale plus
faible mais une volatilité plus élevée
 
|  |  |
|------------------------------------|------------------------------------|
| ![Événements de tempête majeurs affectant la charge](../assets/forecasting/storm.png) | ![](../assets/forecasting/stormlist.png) |

*Impact des tempêtes sur la demande horaire (pannes et récupération)*

**Sensibilité météorologique :** - Relation non linéaire forte entre
température et charge - Les températures extrêmes (en dessous de 20°F,
au-dessus de 90°F) déclenchent une accélération rapide de la demande -
L'humidité et le refroidissement éolien amplifient les effets
météorologiques

![Corrélations météorologiques non lineaire avec la
demande](../assets/forecasting/rawweather.png)

*Relations entre température, vent, précipitations, neige et demande de
pointe quotidienne*

**Ruptures structurelles :** - Post-crise financière de 2008 : plateau
de demande et reprise graduelle - Programmes d'efficacité énergétique :
réduction graduelle de la charge de base - Événements de réponse à la
demande : réductions de charge brutales et temporaires pendant la
tarification de pointe

**Philosophie de traitement des valeurs aberrantes :**

Une attention particulière a été accordée au **traitement des valeurs
aberrantes**—seuls les incidents qui ont clairement perturbé les schémas
de charge ont été ajustés, pour éviter de sur-lisser les signaux de
stress opérationnel réels.

Pourquoi cela importe : - **Sur-nettoyage** des données supprime des
informations précieuses sur le comportement du système sous stress -
**Sous-nettoyage** des données entraîne les modèles sur des anomalies
qui ne se généraliseront pas - La bonne approche : **auditer les valeurs
aberrantes manuellement, comprendre les causes profondes, imputer
seulement si nécessaire**

Par exemple : - Panne majeure de tempête affectant 500k+ clients →
**Imputé** (pas représentatif de la charge normale) - Canicule
entraînant une demande de pointe record → **Conservé** (c'est exactement
ce que le modèle doit apprendre)

C'est la différence entre **la commodité statistique** et **la
pertinence opérationnelle**.

------------------------------------------------------------------------

### Ingénierie des caractéristiques

La prévision a été formulée comme un **problème de régression avec
structure temporelle**—combinant l'interprétabilité de la régression
avec la dynamique temporelle d'ARIMA.

**Caractéristiques clés ingéniérées :**

**1. Indices de confort thermique :** - **Heating Degree Days (HDD) :**
Capture la demande de chauffage lorsque la température descend en
dessous de 65°F - **Cooling Degree Days (CDD) :** Capture la demande de
climatisation lorsque la température dépasse 65°F - **Indicateurs de
refroidissement éolien :** Ajuste la température perçue pour les effets
du vent

``` r
# Heating et Cooling Degree Days
df$HDD <- pmax(65 - df$temperature, 0)
df$CDD <- pmax(df$temperature - 65, 0)
```

![Corrélations météorologiques non lineaire avec la
demande](../assets/forecasting/cddhdd.png)

**2. Variables météorologiques décalées :** - **Température Lag 1 et Lag
2 :** Tient compte de l'inertie thermique dans les bâtiments -
**Précipitations Lag 1 :** Capture les réponses comportementales
retardées

**3. Effets calendaires :** - **Indicateurs de jour de semaine :**
Lun-Ven vs. week-ends ont des profils de charge fondamentalement
différents - **Indicateurs de jours fériés :** Les jours fériés majeurs
présentent des schémas distincts - **Heure de la journée :** Capture les
cycles de demande intrajournaliers

![Schémas hebdomadaires de
demande](../assets/forecasting/sesonalite.png)

*Profils de demande hebdomadaire typiques montrant les variations
jour/semaine*

**4. Structure autorégressive via erreurs ARMA :**

Au lieu d'une régression pure, les modèles ont été spécifiés comme
**régression avec erreurs ARMA**, capturant à la fois : - **Facteurs
exogènes** (météo, calendrier) via coefficients de régression -
**Autocorrélation temporelle** (persistance, tendances à court terme)
via structure ARMA

On considère un modèle de régression dynamique avec erreurs ARMA$(2,1)$
:

\[ y_t = \mathbf{x}\_t\^\top \boldsymbol{\beta} + u_t \]

où :

\begin{itemize}
  \item $y_t$ représente la charge électrique au temps $t$,
  \item $\mathbf{x}_t$ est le vecteur des variables exogènes (conditions météorologiques),
  \item $\boldsymbol{\beta}$ est le vecteur des coefficients de régression,
  \item $u_t$ est un terme d'erreur autocorrélé.
\end{itemize}

Le processus d'erreur suit un modèle ARMA$(2,1)$ :

\[ u_t = \phi*1 u*{t-1} + \phi*2 u*{t-2} + \varepsilon\_t + \theta*1*
\varepsilon{t-1}, \qquad \varepsilon\_t \sim \mathcal{N}(0, \sigma\^2)
\]

Ce modèle correspond à une spécification ARIMA$(2,0,1)$ avec variables
exogènes, estimée par maximum de vraisemblance.

**5. Injection réaliste de bruit de prévision de température :**

Pour refléter l'incertitude du monde réel, **du bruit de prévision de
température** a été injecté dans les entrées de régression, simulant des
erreurs de prévision météorologique réalistes.

Ceci est critique parce que : - En production, vous n'avez pas la
température **réelle**—vous avez la température **prévue** - Les
prévisions météorologiques ont une incertitude inhérente (erreur typique
de ±2-3°F) - Les modèles entraînés sur une météo parfaite performent
moins bien en production que les modèles entraînés sur une météo bruitée

\[ \tilde{T}\_t = T_t + \varepsilon\_t \]

où :

\begin{itemize}
  \item $T_t$ est la température observée au temps $t$,
  \item $\tilde{T}_t$ est la température de prévision,
  \item $\varepsilon_t \sim \mathcal{N}(0, \sigma_T^2)$ est une erreur de prévision gaussienne.
\end{itemize}

Dans nos simulations, l’écart-type de l’erreur de prévision est fixé à
$\sigma_T = 2.5$ degrés Fahrenheit, ce qui correspond à une incertitude
réaliste à court terme dans les prévisions de température.

**C'est ce qui sépare la prévision académique de la prévision
opérationnelle :** s'entraîner sur les données que vous aurez
réellement, pas sur les données que vous souhaiteriez avoir.

------------------------------------------------------------------------

### Modèles évalués

Une large gamme de modèles a été comparée selon un **protocole de
validation glissante**—pas une seule division train/test, mais une
validation répétée sur plusieurs fenêtres temporelles pour évaluer la
stabilité.

**Familles de modèles testées :**

**1. Références naïves :** - **Prévision naïve :** Demain =
Aujourd'hui - **Naïf saisonnier :** Demain = Même jour la semaine
dernière

**2. Lissage exponentiel :** - **SES (Simple Exponential Smoothing) :**
Moyenne pondérée des observations passées - **Méthode de Holt :** Ajoute
une tendance linéaire - **Holt-Winters :** Ajoute des composantes
saisonnières - **ETS (Error-Trend-Seasonal) :** Sélection automatisée
des composantes de lissage - **TBATS :** Saisonnalité complexe avec
termes de Fourier

**3. Famille ARIMA :** - **SARIMA :** ARIMA saisonnier avec
transformation Box-Cox - **SARIMAX :** SARIMA avec variables
météorologiques exogènes

**4. Basés sur la régression :** - **Régression linéaire avec erreurs
ARMA :** Combine interprétabilité et structure temporelle - **ARX
(Autoregressive Exogenous) :** Régression avec dynamique autorégressive

**5. Apprentissage automatique (exploration, pas production) :** -
**Random Forest :** Ensemble d'arbres de décision - **Gradient Boosting
(XGBoost) :** Boosting séquentiel - **LSTM (RNN) :** Apprentissage
profond pour données séquentielles

**Protocole d'évaluation :**

Les modèles ont été évalués en utilisant : - **MAPE (Mean Absolute
Percentage Error) :** Métrique de précision standard de l'industrie -
**RMSE (Root Mean Squared Error) :** Pénalise davantage les grandes
erreurs - **MAE (Mean Absolute Error) :** Robuste aux valeurs aberrantes

Avec des décompositions saisonnières (Hiver, Printemps, Été, Automne) et
comparaison statistique via **tests de Diebold-Mariano** pour déterminer
si les différences de performance étaient statistiquement
significatives.

**Validation glissante :** - Entraînement sur 8 ans de données - Test
sur les 6 prochains mois - Avancer de 3 mois - Répéter

Cela garantit que les modèles sont évalués sur leur capacité à **se
généraliser dans le temps**, pas seulement à s'ajuster aux schémas
historiques.

------------------------------------------------------------------------

### Résultats clés

**Résumé de la performance :**

✅ **La régression linéaire avec bruit de température réaliste** a
systématiquement surpassé les modèles de séries temporelles classiques à
travers **Hiver, Printemps et Été**

✅ Performance en Automne comparable entre plusieurs modèles
(variabilité de demande plus faible réduit la différenciation des
modèles)

❌ Les modèles classiques (SARIMA, Holt-Winters, ETS, TBATS) ont montré
**une dégradation systématique** dans les périodes volatiles ou
irrégulières (vagues de froid, canicules, transitions post-vacances)

❌ Les références naïves ont échoué à capturer la dynamique saisonnière
et la sensibilité météorologique

![Comparaison des erreurs MAPE par saison - Modèles
naïfs](/path/to/graphics_naive_comparison.png) *Source :
Graphics_JCPL_Final.pdf - Pages 10-11 - Performance des méthodes naïves
et de lissage simple par saison*

**Comparaison quantitative (moyenne sur les saisons) :**

| Modèle                        | MAPE (%) | RMSE (MW) | MAE (MW) |
|-------------------------------|----------|-----------|----------|
| Naïf                          | 8.2      | 420       | 310      |
| Naïf saisonnier               | 6.5      | 380       | 285      |
| Holt-Winters                  | 4.8      | 295       | 225      |
| SARIMA                        | 4.2      | 270       | 210      |
| ETS                           | 4.0      | 265       | 205      |
| **Régression + ARMA + Bruit** | **3.4**  | **235**   | **180**  |

![Performance des modèles de lissage
exponentiel](/path/to/graphics_exponential_smoothing.png) *Source :
Graphics_JCPL_Final.pdf - Pages 12-15 - Holt, Holt-Winters
additif/multiplicatif, ETS avec erreurs par saison*

**Pourquoi la régression a gagné :**

1.  **Intégration météorologique :** Les caractéristiques explicites de
    température, HDD/CDD ont mieux capturé les effets météorologiques
    non linéaires que la saisonnalité implicite de SARIMA
2.  **Entraînement réaliste :** L'injection de bruit de prévision a
    rendu le modèle robuste aux erreurs de prévision météorologique
3.  **Interprétabilité :** Les coefficients ont une signification
    opérationnelle claire (ex. "1°F d'augmentation → 50 MW
    d'augmentation de charge")
4.  **Stabilité :** La performance ne s'est pas dégradée brutalement
    pendant les événements extrêmes

![Construction et impact du refroidissement
éolien](/path/to/graphics_windchill.png) *Source :
Graphics_JCPL_Final.pdf - Page 16 - Construction du refroidissement
éolien et son impact sur la demande*

![Diagnostics de régression
linéaire](/path/to/graphics_regression_diagnostics.png) *Source :
Graphics_JCPL_Final.pdf - Pages 17-21 - Diagnostics résiduels et
ajustement du modèle de régression*

**Modes d'échec des modèles classiques :**

-   **SARIMA :** A eu du mal avec les ruptures structurelles (événements
    de réponse à la demande, changements économiques)
-   **Holt-Winters :** Sur-lissage pendant les transitions rapides
    (vagues de froid soudaines)
-   **TBATS :** Coûteux en calcul, amélioration marginale par rapport
    aux modèles plus simples
-   **LSTM :** Nécessitait un réglage intensif des hyperparamètres,
    prédictions opaques, pas meilleur que la régression

![ACF/PACF et analyse de stationnarité](/path/to/graphics_acf_pacf.png)
*Source : Graphics_JCPL_Final.pdf - Pages 22-29 - Fonctions
d'autocorrélation et tests de stationnarité*

![Diagnostics des modèles
ARIMA/SARIMA](/path/to/graphics_arima_diagnostics.png) *Source :
Graphics_JCPL_Final.pdf - Pages 30-33 - Diagnostics résiduels pour
différentes spécifications ARIMA*

L'approche basée sur la régression a atteint un **équilibre solide entre
précision, robustesse et interprétabilité**, la rendant appropriée pour
le déploiement opérationnel.

------------------------------------------------------------------------

### Considérations de mise en œuvre et de déploiement

**Ce qui a rendu ce modèle prêt pour la production :**

✅ **Pipeline automatisé d'ingénierie de caractéristiques :**
Reproductible, testable, sous contrôle de version

``` python
def engineer_features(df_raw):
    """
    Transformer les données brutes de charge et météo en caractéristiques 
    prêtes pour le modèle.
    """
    df = df_raw.copy()
    
    # Indices thermiques
    df['HDD'] = np.maximum(65 - df['temperature'], 0)
    df['CDD'] = np.maximum(df['temperature'] - 65, 0)
    
    # Décalages
    df['temp_lag1'] = df['temperature'].shift(1)
    df['temp_lag2'] = df['temperature'].shift(2)
    
    # Calendrier
    df['weekday'] = df['timestamp'].dt.dayofweek
    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
    df['hour'] = df['timestamp'].dt.hour
    
    # Injecter du bruit réaliste
    df['temp_forecast'] = df['temperature'] + np.random.normal(0, 2.5, len(df))
    
    return df
```

✅ **Réentraînement glissant :** Modèle réajusté chaque semaine avec les
dernières données pour s'adapter aux changements structurels

✅ **Surveillance et alertes :** Suivi des erreurs de prévision en temps
réel, alerte lorsque le MAPE dépasse les seuils

✅ **Communication avec les parties prenantes :** Les sorties de
prévision incluent des intervalles de confiance et une analyse de
scénarios (météo optimiste/pessimiste)

**Ce qui n'a pas été mis en production :**

❌ **Modèles LSTM :** Trop opaques, nécessitaient des GPU, gain de
performance marginal ne justifiait pas la complexité

❌ **Méthodes d'ensemble :** L'empilage de plusieurs modèles a augmenté
la charge de maintenance sans amélioration de fiabilité

❌ **Prévision ultra-court terme (15 min à l'avance) :** Le besoin
opérationnel était jour-à-jour ; ajouter de la complexité pour 15 min
n'ajoutait pas de valeur

------------------------------------------------------------------------

### Points à retenir

Ce projet a renforcé un principe clé :

> **Dans la prévision opérationnelle, la robustesse sous incertitude
> compte plus que l'optimalité théorique sous information parfaite.**

Les modèles basés sur la régression avec des prédicteurs bien choisis
restent hautement compétitifs lorsqu'ils sont combinés avec : - **Des
hypothèses réalistes** (prévisions météo bruitées, pas des valeurs
réelles parfaites), - **Des protocoles d'évaluation appropriés**
(validation glissante, décompositions saisonnières, tests
statistiques), - **Des contraintes opérationnelles** (interprétabilité,
faisabilité computationnelle, surveillance).

**Leçons plus larges :**

1.  **Injecter du réalisme tôt :** S'entraîner sur des données parfaites
    crée des modèles fragiles
2.  **Valider à travers les saisons :** Un modèle qui fonctionne en été
    peut échouer en hiver
3.  **Prioriser l'interprétabilité :** Les opérateurs doivent comprendre
    *pourquoi* une prévision a changé
4.  **Se méfier de la complexité pour la complexité :** LSTM n'a pas
    battu la régression parce que la structure du problème favorisait
    l'ingénierie explicite de caractéristiques

**C'est la différence entre la prévision comme exercice statistique et
la prévision comme capacité opérationnelle.**

------------------------------------------------------------------------

**Stack technique :**\
Python · Statsmodels · Scikit-learn · Pandas · NumPy · Matplotlib ·
Seaborn

**Dépôt :**\
[GitHub – Prévision de la demande
d'électricité](https://github.com/MBalogogGLemuel) *Bientôt disponible*

**Travaux connexes :**\
- [Pourquoi la faisabilité compte plus que
l'optimalité](/blog/feasibility-over-optimality) - [L'IA peut-elle
vraiment réfléchir à la conception de modèles ?](/blog/ai-model-design)

------------------------------------------------------------------------

*La prévision ne consiste pas à prédire l'avenir.*\
*Il s'agit de prendre des décisions aujourd'hui qui restent robustes
demain.*
